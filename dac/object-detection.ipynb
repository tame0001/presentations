{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the world of computer, everything becomes numbers. \n",
    "That includes images. \n",
    "Computer sees images or pictures as a grid of numbers, or mathematically speaking Matrix. \n",
    "Each cell or element of the matrix represents Pixel of the image. \n",
    "The value of each cell can be \n",
    "- binary (0 or 1) for black & white images\n",
    "- 0 - 255 for 8-bit gray scale images\n",
    "- a set of 3 numbers for RGB images\n",
    "\n",
    "The location or coordinate of each pixel is also important. \n",
    "Each image is 2-D plane, therefore, the coordinate is (x, y).\n",
    "Please note that the origin (0, 0) locates on the top-left corner.\n",
    "This is different than the mathematical number plane.\n",
    "Additional, the number 1 is added as the third element of the coordinate.\n",
    "For example, the pixel (0, 1) will be \n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "0\\\\\n",
    "1 \\\\\n",
    "1\n",
    "\\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To move the pixel's location, we multiply a location with a 3x3 matrix. \n",
    "For example,\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "1 \\\\\n",
    "3 \\\\\n",
    "1\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "1 & 0 & 1 \\\\\n",
    "0 & 1 & 2 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "0 \\\\\n",
    "1 \\\\\n",
    "1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "The pixel is moved from (0, 1) to (1, 3). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That 3x3 dictates how pixels move from one 2-D plane to another 2-D plane. The bottom-right element must be 1 all the time. That leave 8 variable to be resolved. Therefore, we need 8 variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our target is to move a distorted view of the area to a flat 2-D plane. Then, we can do object detection and locate the robots. As we need 8 equations, we will pick 4 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import cv2 as cv # computer vision\n",
    "import numpy as np # Numpy for matrix operation\n",
    "from pathlib import Path # file exploration\n",
    "from PIL import Image # image library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an image's path\n",
    "path = Path(\"../img\") / 'cv-example1.jpg'\n",
    "# load the image\n",
    "img = Image.open(path)\n",
    "img # display the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the 4 corners (from other software)\n",
    "corners = [(266, 51), (544, 144), (56, 250), (380, 405)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(img) # convert image to numpy (matrix)\n",
    "for point in corners:\n",
    "    img = cv.circle(img, point, 5, (255, 0, 0)) # draw corner for verification\n",
    "Image.fromarray(img) # to display, we need to convert back to PIL's Image format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will map the four selected corners to these new coordinates\n",
    "target = [(0, 0), (300, 0), (0, 300), (300, 300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the image again (with no red circle)\n",
    "img = Image.open(path)\n",
    "img = np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have 8 equations to find the transformation matrix\n",
    "H = cv.getPerspectiveTransform(\n",
    "    # this function requires float 32 bit data type\n",
    "    np.array(corners, dtype=\"float32\"), np.array(target, dtype=\"float32\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the transformation\n",
    "img_flat = cv.warpPerspective(img, H, (300, 300))\n",
    "Image.fromarray(img_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step we want to locate the object of interest, in this case, a Raspberry Pi box. There are several ways to tackle this issue. Mainly traditional image processing and deep learning. We will explore the former method for this tutorial. \n",
    "\n",
    "Let's think about how our eyes and brain locate the object from the background, one obvious way is to look for color differences. There are other factors come to play as well such as texture. But we will explore the color world first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computer see images as combination of 3 layers red, green, and blue (RGB).\n",
    "# ** if you load image by OpenCV, the order of color will be BRG. \n",
    "# we load this one with PIL, so it is in RGB\n",
    "Image.fromarray(img_flat[:, :, 0]) # red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(img_flat[:, :, 1]) # blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(img_flat[:, :, 2]) # green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB is the most common color space but there are many more. For example, we will explore Hue, Saturation, and Value (HSV)\n",
    "img = cv.cvtColor(img_flat, cv.COLOR_BGR2HSV) # convert to HSV\n",
    "Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(img[:, :, 0])  # hue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(img[:, :, 1])  # saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(img[:, :, 2])  # value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = cv.inRange(img, np.array([0, 100, 0]), np.array([255, 255, 255])) # put a mark for pixel that has saturation more than 100\n",
    "Image.fromarray(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, _ = cv.findContours(mask, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE) # find contours\n",
    "Image.fromarray(cv.drawContours(img_flat.copy(), contours, -1, (0, 255, 0), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours = [\n",
    "    cnt for cnt in contours if cv.contourArea(cnt) > 20 and cv.contourArea(cnt) < 100\n",
    "] # only keep contours that fit our criteria\n",
    "Image.fromarray(cv.drawContours(img_flat, contours, -1, (0, 255, 0), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the center coordinate\n",
    "cnt = contours[0]\n",
    "moment = cv.moments(cnt)\n",
    "x = int(moment[\"m10\"] / moment[\"m00\"])\n",
    "y = int(moment[\"m01\"] / moment[\"m00\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the coordinate\n",
    "cv.putText(\n",
    "    img_flat,\n",
    "    f\"{x}, {y}\",\n",
    "    (x - 20, y - 20),\n",
    "    cv.FONT_HERSHEY_SIMPLEX,\n",
    "    0.5,\n",
    "    (0, 0, 0),\n",
    "    2,\n",
    ");\n",
    "Image.fromarray(img_flat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asm591",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
